{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYAVxMNlmwqD"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"creditcard.csv\")  # Replace with your dataset path\n",
        "print(\"Dataset loaded successfully.\")\n",
        "\n",
        "# Display basic info\n",
        "print(df.head())\n",
        "print(\"\\nClass Distribution:\\n\", df['Class'].value_counts())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
        "\n",
        "# Normalize the 'Amount' column\n",
        "scaler = StandardScaler()\n",
        "df['Amount_Norm'] = scaler.fit_transform(df[['Amount']])\n",
        "df.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Handle imbalance using SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "\n",
        "print(\"\\nAfter SMOTE:\")\n",
        "print(\"Resampled Class Distribution:\\n\", pd.Series(y_res).value_counts())\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res\n",
        ")\n",
        "\n",
        "# Train a Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Feature Importance (Optional)\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "features = X.columns\n",
        "\n",
        "# Plot top 10 features\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importances (Top 10)\")\n",
        "sns.barplot(x=importances[indices[:10]], y=features[indices[:10]])\n",
        "plt.show()\n"
      ]
    }
  ]
}